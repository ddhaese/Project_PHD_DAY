[["time-series.html", "Workshop 2 Time Series 2.1 Introduction to time series 2.2 Uploading the data 2.3 Colors 2.4 Data exploration 2.5 Prepare data 2.6 Graphing time series 2.7 Time series analyzes 2.8 Decompose time series 2.9 Predictions 2.10 Extra: Resampling temporal data", " Workshop 2 Time Series 2.1 Introduction to time series In this workshop we will learn how to handle and visualize temporal data. Most analytic tools dealing with time series depend on the ts class of objects and so we will have to learn how to transform our source data to a ts object. Finally, we will be plotting the results of some diagnostic and predictive analyses typical for time series data. 2.2 Uploading the data At the end of the workshop you will have the opportunity to work with the same dataset as for the Boxplot workshop, but because that data is slightly more difficult to use for time series analysis, we will first start with a simpler dataset. On Kaggle you will find the dataset called [Time Series Data] (https://www.kaggle.com/yugagrawal95/timeseries-data). The data is originally made available as an Excel workbook, but we will be using the same data converted into a tsv file. This dataset consists of the sales figures of a number of products along with several other variables that will not be used here. Excel is often very problematic as a data source, so if you can avoid it, preferably use a format that will still be understood 2000 years from now: plain text, preferably tab-separated values (.tsv) so that values with commas need not to be escaped with double quotes. We use data.table to upload the data. This package currently offers the most professional way to manipulate data. The fread method is flexible and allows you to: load very fast and very large datasets parse text directly as data (i.e. fread (\"A,B\\n1,2\\n3,4\")) select variables as well as instances run a shell command to add a pre-processing step set the data type the variables should be interpreted as include the character encoding of a file (i.e. UTF-8) define the primary key in case of relational data directly open data from within an archive (i.e. fread (\"dev.gz\")) In your new Rmd file, delete the sample code and add the code below: --- title: &quot;Timeseries&quot; author: &quot;Your name here&quot; date: &quot;Published on 2021-03-16&quot; output: html_document: highlight: zenburn --- ## Workshop Time Series ... Enter in your name and replace ... with a new R code block (eng: code chunk) using the shortcut Ctrl + Alt + I Make sure in a rMArkdown file to add an empty line before and after each code block, title and list Add the code below in this block (additional info to come): library(knitr) library(data.table) library(magrittr) library(readxl) library(dplyr) library(ISOweek) library(lubridate) library(forecast) opts_chunk$set(echo = TRUE) sales &lt;- fread(, &quot;dat/sales.tsv&quot;) With the various library expressions, the necessary packages are loaded into memory. If these lines generate an error, it is usually means the package needs installing first. If so, use an expression such as install.packages (c (\" data.atble \",\" magrittr \")) in the console to install the missing packages. Let us now briefly review why we need these packages: knitr: parsing the RMarkdown to an HTML report data.table: loading and manipulating data magrittr: using [method chaining] (https://en.wikipedia.org/wiki/Method_chaining#:~:text=Method%20chaining%2C%20also%20known%20as,to%20store%20the%20intermediate % 20results.) dplyr: alternative to manipulating data ISOweek: converting from date to week numbers and vice versa, according to [ISO 8601] (https://en.wikipedia.org/wiki/ISO_8601) standards lubridate: expression of a date as a decimal number forecast: wrapper to run forecasts onts objects Note that for demo purposes two alternatives are used here for manipulating data. Also note that a lot of effort is put into manipulating date fields. As we will see, handling dates, especially when the data is classified on a weekly basis, can become very complex very rapidly. With the opts_chunk$set function (actually function set that is an element of the list opts_chunk) we ensure that the source code is shown in the report. If the report is distributed to individuals who are not interested in the code, you can set echo = FALSE. 2.3 Colors Create a color palette: palette(c(rgb(.7, .7, .7), &quot;steelblue1&quot;, &quot;black&quot;, &quot;#D3EAF1&quot;)) The above code demonstrates the use of the color palette. Here you see that you can enter colors in different formats. After the palette has been defined, you can refer to the colors by means of their indices 1, 2, &amp; hellip ;. If you havent yet heard about it, you might want to examine the Munsell color space. Munsell was a genius with colors. A full description of his color space is beyond the scope of this workshop, but why not admire one of his so-called color contrasts (dyads): Figuur 2.1: The dyad blue-5 versus yellow-red-5 (5B-5YR). In each colored box you will see from the top down: an index for reference, the Munsell color code, the corresponding RGB values and finally the color represented as a hex triplet. See the [Wikipedia page] (https://en.wikipedia.org/wiki/Munsell_color_system) for more info and [this page] (https://www.rit.edu/cos/colorscience/rc_munsell_renotation.php) of the Rochester Institute of Technology where you will find datasets to produce similar figures. 2.4 Data exploration We are going to keep data exploration here to a minimum. With the str function you can look inside objects such as this sales object. Such a function is typically executed in the console and is not part of the report itself: # In the console... sales %&gt;% str ## Classes &#39;data.table&#39; and &#39;data.frame&#39;: 935 obs. of 86 variables: ## $ Key : chr &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ... ## $ Date : POSIXct, format: &quot;2014-01-01&quot; &quot;2014-01-01&quot; ... ## $ Volume : num 1346974 677826 1210359 436761 434 ... ## $ Disc : num 4.29e+08 1.16e+08 1.04e+08 5.63e+07 2.94e+05 ... ## $ max_T : num 49.5 49.5 49.5 49.5 49.5 ... ## $ min_T : num 29.7 29.7 29.7 29.7 29.7 ... ## $ avg_T : num 39.6 39.6 39.6 39.6 39.6 ... ## $ precipitation : num 0.448 0.448 0.448 0.448 0.448 ... ## $ Consumer_Price_Index_month : num 85.5 85.5 85.5 85.5 85.5 ... ## $ Exchange_Rate_Index_Period_Average_month : num 109 109 109 109 109 ... ## $ Exchange_Rate_LCU_per_US_Period_Average_month : num 6.83 6.83 6.83 6.83 6.83 ... ... We see that there are a number of products (under Key), a date of sale (Date) and sales Volume. As you can see there are many more variables, but with these three we should be able to get started to demonstrate the basics. 2.5 Prepare data The particular thing about time series (but also, for example, GIS data) is that the dependent variables do not only depend on other variables, but also on themselves. We speak of autocorrelation when a value depends on a neighbouring value either through space or time. To conduct a time series in R, you are best to work with ts class objects (stands for time series). In order to do that, we first need to pivot the data: sales &lt;- sales %&gt;% dcast(Date ~ Key, value.var = &quot;Volume&quot;) Date A B C D E F G H I J K L M N 2014-01-01 1346974 677825.9 1210358.5 436760.7 433.99 1229415.4 790802.1 NA NA NA NA NA NA NA 2014-02-01 1058681 442605.0 829241.9 205538.3 699.10 885082.1 507910.2 NA NA NA NA NA NA NA 2014-03-01 1089615 550634.4 1100553.1 262253.8 1421.69 1191730.8 612966.6 NA NA NA NA NA NA NA 2014-04-01 1073261 665210.9 1316461.4 351818.4 1758.77 1357049.5 879226.3 278106.2 NA NA NA NA NA NA 2014-05-01 1289022 811401.7 1515828.5 309505.0 2275.23 1713073.1 1041092.3 389241.8 NA NA NA NA NA NA 2014-06-01 1491953 915308.1 1731305.7 339498.8 2894.75 1887919.4 1292278.0 501514.3 NA NA NA NA NA NA This pivoting is rather exceptional in statistical analyses and is mainly encountered in autocorrelated data (see also the term repeated measures). Now we select three products and also apply a Date filter because some values are missing at the end of the time series. Then we convert the data to a ts object: sales_ts &lt;- sales[ Date &lt; &quot;2020-02-01&quot;, # Filter by date .(A, C, E)] %&gt;% # Selecte features ts(frequency = 12, # Convert to ts, 12 months per year start = c(2014, 1)) # Provide start of the time series 2.6 Graphing time series Once everything is in the correct format, it is as simple as calling the plot function: par(bg = 4, cex.main = 1) main &lt;- &quot;Sales figures\\nfor three products&quot; sales_ts %&gt;% plot(main = main, xlab = &quot;Year&quot;) Close, but no cigar. There is still an issue with the y-axes. The position of the labels on the axes in base R is determined by a functionpretty. So you could turn off the y-axes in the plot (yaxt = \"n\") and plot them all manually using the axis function. Of course, it is much easier to divide the numbers by a factor 1000. Adjust the previous code to divide the sales figures by 1000 and than adjust the title of the figure: sales_ts_th &lt;- sales_ts / 1000 par(bg = 4, cex.main = 1) main &lt;- &quot;Sales figures (x1000)\\nfor three products&quot; sales_ts_th %&gt;% plot(main = main, xlab = &quot;Year&quot;) 2.7 Time series analyzes This is not a workshop on analyses, but in reality the analyses and the visualization go hand-in-hand. After all, visualization often serves as a diagnostics tool. Let us measure the amount of cross-correlation among the sales of our three selected products. Examine the auto- and cross-correlation for all combinations of the sales volumes for the products A, c and E. Do this for a horizon of 18 months in the future (positive) and in the past (negative): par(bg = 4) sales_ts_th %&gt;% acf(lag.max = 18) From this we learn, for example, that there is a correlation between products A and E with a horizon of 1 season (1 year in this case), but that the relationship is not completely symmetrical. In other words one event seems to preceed the other and that may be en important hint to analyse possible causal dependencies. To see this, compare the correlation at 1.0 for A &amp; E (below the dashed blue line indicating the significance level) with that of -1.0 for E &amp; A (above significance level). 2.8 Decompose time series Lets break the sales figures for one product, namely product C, into a seasonal effect (the purely repetitive part), the trend (background level) and the residual noise: par(bg = 4) sales_ts_th[, &quot;C&quot;] %&gt;% stl(s.window = &quot;periodic&quot;) %&gt;% plot Note that the problem of the axes is solved here by alternating the position of the y-axis. Investigate how the plot of a stl object causes the axes to be displayed alternately: stats:::plot.stl 2.9 Predictions Let us predict the future, more specifically the sales figures for the year 2019. Note that we just have those figures, why would we predict them? Because it is of course good to immediately test the prediction against reality, otherwise we have to wait a year and the organizers of this workshop voted against :-) Let us take the standard plot for multivariate forecast objects: par(bg = 4) sales_ts_th %&gt;% forecast %&gt;% plot(col = 3, xlab = &quot;Year&quot;, main = &quot;Items sold (x 1000)&quot;) This is already quite good, but there are some problems. Lets start with an important detail: the color and shades of the prediction intervals. With fan you can obtain more color shades and withcolorRampPalette we make a simple color shade: par(bg = 4) ramp &lt;- colorRampPalette(1:2)(25) sales_ts_th %&gt;% forecast(fan = TRUE) %&gt;% plot(col = 3, xlab = &quot;Year&quot;, shadecols = ramp, main = &quot;Items sold (x 1000)&quot;) Now comes the main problem: we really only want to forecast only 2019 and we want to see the current and forecast data superposed. It would also be nice if there were a clear marking at the start of the prediction. Try to reproduce the predictions with the above requirements: par(bg = 4, mfrow = c(3, 1), oma = c(5, 3, 1, 1), mar = c(0, 4, 0, 2)) for(series_name in sales_ts %&gt;% colnames) { series &lt;- sales_ts_th[, series_name] fc &lt;- series %&gt;% window(end=c(2019, 1)) %&gt;% forecast(fan = TRUE, h = 12) fc %&gt;% plot(shadecols = ramp, col = 3, xaxt = &quot;n&quot;, main = &quot;&quot;) title(ylab = series_name) if (series_name == &quot;E&quot;) { axis(1) } abline(v = 2019, lwd = 2, col = 1, lty = 3) fc &lt;- series %&gt;% window(start=c(2018, 12)) %&gt;% lines(col = 3) } title(xlab = &quot;Year&quot;, outer = 2) 2.10 Extra: Resampling temporal data Temporal data is often organized on a week, month, quarter, or annual basis. For example sales figures per quarter. In the industry we speak of a bucket and the bucket could be a week, a quarter, etc &amp; hellip ;. Sometimes, however, as with the student data, a date field is provided, but the data is not neatly aggregated into fixed time units. The aggregation, which is also called resampling or bucketising, must then be performed manually. This is demonstrated below for the sake of completeness. sem_1 &lt;- fread(&quot;dat/sem_1_anon.tsv&quot;) We first check the range of the variable Date1, divide it into weeks and add seven days to the end date: sem_1$Datum1 %&gt;% range(na.rm = TRUE) %&gt;% strftime(&quot;%Y-W%V-1&quot;) %&gt;% ISOweek2date %&gt;% add(c(0, 7)) By alternating the dot color per week, we can investigate where there is sufficient data available to perform an analysis on: sem_1[, Week_T := factor(ISOweek(Datum1))] week_lev_all &lt;- sem_1$Week_T %&gt;% levels par(bg = 4) ramp &lt;- rainbow(24, 1) temp_pal &lt;- palette(ramp) sem_1[, plot(Datum1, MemoS_T, col = Week_T, pch = 19, cex = .7, main = &quot;Highlight weeks&quot;, xlab = &quot;Date for review version\\n(&#39;terugblikversie&#39;)&quot;, ylab = &quot;Memorising&quot;)] -&gt; d legend(&quot;bottomright&quot;, legend = week_lev_all, col = ramp, cex = .7, bg = NA, ncol = 4, pch = 19, border = &quot;n&quot;) palette(temp_pal) Finally we can select the portion with suffcient data availble and convert to a ts object: par(bg = 4) sem_1[ grepl(&quot;2020&quot;, Week_T), # Selectie .(MemoS_T = mean(MemoS_T)), # Var-manipulatie Week_T] %&gt;% # Groepering arrange(Week_T) %&gt;% # dplyr select(MemoS_T) %&gt;% ts( freq = 365.25/7, start = decimal_date(ymd(&quot;2020-09-07&quot;))) %&gt;% plot(lwd = 2, xlab = &quot;Tijd (decimaal)&quot;, ylab = &quot;Memoriseren&quot;, main = &quot;Evolutie memoriseren&quot;) "]]
