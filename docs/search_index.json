[["index.html", "Saving your plots Summary", " Saving your plots David DHaese 18-3-2021 Summary This workshop will provide you with the basics on visualizing your data using the statistical package R. The workshop will focus on how to generate frequently used graphics, such as the scatter plot, the (ordered) bar chart or the box and whisker plot. For more experienced users more advanced visuals are added in the form of time series analyses and social network analyses. Participants will be able to practice via exercises. Basic knowledge of R is recommended, and R-studio should be installed prior to the session. A simple dataset will be provided, but participants can also use their own research-data. "],["getting-started.html", "Getting started Installation New project New RMarkdown report", " Getting started Installation In case you havent done this before, install the latest version of R and RStudio New project You can do without but it is considered good practice to define a project folder and corresponding R project, no matter how small the project. On the top of the screen in RStudio you will find the button to allow you create a new project or quickly switch between projects. Making use of a project has the added benefit that R-studio saves all of the generated files (such as visualizations) in the project folder. No need to try and remember where you saved files anymore! Follow the RStudio wizard to create a new project in a folder of your choice (best locally during workshop) New RMarkdown report By default data scientists work with notebooks and for R this means RMarkdown notebook (.rmd extension). Not only do notebooks offer enhanced reproducibility. For one thing, it is easy to integrate R-code and use working R-code to export to various output formats (html, pdf, word) and output types (documents, dashboards, presentations). Once you get used to them, you will find them increasing your productivity: Make a new rMarkdown file through New File &gt; R Markdown Give your HTML document a title (HTML is the default doc type but there are many more) If your RStudio asks for it, let it install the necessary packages You will notice that RStudio has made an example file for you Use the Save-button or Ctrl + S to save it in the root of your project folder (b.t.w., use Alt + Shift + K for an overview of available shortcuts) Let us immediate test the parsing of the report. Run or knit it by pressing the knit-button or use the shortcut Ctrl + Shift K If all goes well, you should see the example report appearing in the viewer pane of your RStudio. "],["visualizing-descriptive-analyses-for-beginners.html", "Workshop 1 Visualizing Descriptive analyses for beginners 1.1 Load data 1.2 Exploring the distribution of the variable Woordenschat (Vocabulary) through a histogram 1.3 Histogram exercises 1.4 Exploring the distribution of a Departement using barplots 1.5 Barplot exercises 1.6 Expansion: Grouped &amp; stacked barplots 1.7 Boxplots 1.8 Exercise time 1.9 Whats next?", " Workshop 1 Visualizing Descriptive analyses for beginners 1.1 Load data The data file contains the results of +- 4000 unique students who participated in the begin assessment environment at AP, called AP-Vaardig. Students could participate in assessments on Language skills Mathematics Study motivation Learning strategy use In addition to these core-variables we obtained some background variables such as Department, Study program (Opleiding) and Program type (Professionele bachelor or graduaat). We also included students average score on their exams in January (GPA; Grade Point Average). All variable names are in Dutch. There are multiple ways of importing data files in R-studio. The most straightforward is using the user interface in RStudio. You can access this via Environment &gt; Import Dataset &gt; From Excel. If you are using RStudio for the first time, the program might ask you to download and install some packages. Just agree to installing and let the installation finish. The data file you have to import can be found in the chat or on this location: https://github.com/ddhaese/Project_PHD_DAY/tree/main/dat Save the code in your project folder for convenience. Youll notice that RStudio wrote some code in your console. This is the code the Import Dataset wizard used to import the data file. Y can use this code to import the data in RStudio in the future, instead of using the import wizard. You can also amend this code later, for instance by adding code to define NA-values: library(readxl) sem_1_anon &lt;- read_excel(&quot;dat/sem_1_anon.xlsx&quot;) View(sem_1_anon) The data is saved in an R-object called sem_1_anon en if you look under the Environment tab, you should see this object appear. The last line of the code above opens your data file in the RStudio viewer. For data files from a small to moderate size this is a convenient way to explore your data. You can also retrieve the data type RStudio assigned to each variable by hovering over the variable name/column name. This might help you explain why RStudio is not willing to produce a certain visual (i.e. because it interpreted a numerical variable as a factor (ordinal variable)). You can get similar information by clicking open the object in the Environment-tab. This is especially convenient for a large data set if you want to look up how a certain variable in your set is labeled. A third way to consult the content of any object in R is to use thestr function. Copy the code below in your console and you should see a long list of all variables and their data types. You also get an indication of the length of the columns and a sample with the values of the first couple of rows. Finally, you can see that this object is a tibble, a table derived from a data.frame. (for those who are interested: a tibble is a format that belongs to the tidyverse, a cluster of integrated R-packages aimed at tidying, wrangling, visualizing and presenting data: https://www.tidyverse.org/). # In de console: str(sem_1_anon) ## tibble [3,811 x 71] (S3: tbl_df/tbl/data.frame) ## $ ID : num [1:3811] 1 2 3 4 5 6 7 8 9 10 ... ## $ Inschrijving : chr [1:3811] &quot;Nee&quot; &quot;Nee&quot; &quot;Nee&quot; &quot;Nee&quot; ... ## $ Generatiestudent : chr [1:3811] &quot;Nee&quot; &quot;Nee&quot; &quot;Nee&quot; &quot;Nee&quot; ... ## $ Departement : chr [1:3811] &quot;MC&quot; &quot;MC&quot; &quot;MC&quot; &quot;MC&quot; ... ## $ Opleiding : chr [1:3811] &quot;Bachelor in het bedrijfsmanagement (rechtspraktijk)&quot; &quot;Bachelor in het office management&quot; &quot;Bachelor in het communicatiemanagement&quot; &quot;Bachelor in het office management&quot; ... ## $ Opleidingstype : chr [1:3811] &quot;Bachelor&quot; &quot;Bachelor&quot; &quot;Bachelor&quot; &quot;Bachelor&quot; ... ## $ Woordenschat : num [1:3811] 70 65 60 60 45 70 55 50 65 95 ... ## $ Lidwoorden : num [1:3811] NA 80 76 62 66 NA 78 NA 92 82 ... ## $ Werkwoordspelling : num [1:3811] NA 73.3 60 73.3 73.3 ... ## $ Algemene_spelling : num [1:3811] NA 52.5 77.5 60 55 NA 65 NA 82.5 NA ... ## $ Woordvorming : num [1:3811] NA 34 36 50 14 NA 32 NA 28 46 ... ## $ Tekstanalyse : num [1:3811] NA 70 80 65 70 NA 65 NA NA NA ... ## $ Correcte_taal : num [1:3811] NA 60.9 69.6 78.3 65.2 ... ## $ Email : num [1:3811] NA 60 90 50 40 NA 30 NA NA NA ... ... Lets switch to our newly generated example Rmd-file. Delete all example code (or start below the code if you want to retain it for further inspection later on). For those who want to delete: everything below ## R Markdown is ok. Next, make a new title: ## Loading the data followed by an empty line (## tells R-Markdown to make a title at the second level). Below the title, insert a code chunk. Click insert (somewhere on the top right of the window where you can view your Rmd-file). In the drop-down menu, select the code chunk you want to insert: R-code in this case (actually two separate code chunks :) ). Paste the code from console in the chunks according to the example bellow: ```{r setup, include=FALSE} library(readxl) ``` ```{r load-data} sem_1_anon &lt;- read_excel(&quot;dat/sem_1_anon.xlsx&quot;) View(sem_1_anon) ``` Pro tip 1: It is convenient to start each new document with a code chunk in which you load not only your data, but also all the packages you will use in your analyses. I personally have a list of frequently used packages I copy/paste in this chunk across all my projects. Pro tip 2: You can see the idea of a notebook taking shape here: within the R-code chunks you execute your analyses or create your visualizations. Between the chunks you can write down interpretations, intriguing results or questions for your supervisor. You can easily structure your notebook by adding titles (remember the ## title, followed by an empty line) you can print the entire document by clicking the knit button in the menu bar in the top left corner. This will produce a html-page including all calculations and visuals, but also the text and titles in between (so the entire notebook) Now, lets turn to visualizing our data (finally). 1.2 Exploring the distribution of the variable Woordenschat (Vocabulary) through a histogram As stated above: our dataset is composed of various test results and some background variables in the columns and participating students as rows. Lets start exploring our data by visualizing some of the variables (exploratory data visualization). To get started we have to load the required packages. In R this is a two step procedure: First, you have to download the packages to your computer (via install.packages). Second you have to activate the packages in R (via library). You have to download the packages only once, but have to activate them for each session. # In de console (enkel eenmalig bij eerste gebruik): install.packages(c(&quot;data.table&quot;, &quot;magrittr&quot;, &quot;tidyverse&quot;)) Pro tip 3: We prefer not to incorporate our install.packages commands in our Rmd-file. Otherwise R would download these packages every time we would run our code. That would slow down the computing time significantly. You can paste the code bellow after previous library-statements. library(readxl) library(data.table) library(magrittr) library(tidyverse) Pro tip 4: I would add these to the first load chunk at the top of the Rmd-file. We will now examine the distribution of the variable woordenschat. Observe how the code is constructed below: We define which colors we want to use by identifying a palette. So col = 1 means aliceblue and col = 2 indicates black. We can use this palette throughout the whole document if are looking for consistency in our visualizations. We could also add more colors to this list (e.g. all branding colors from our organization). We select the variable from the sem_1_anon dataset by stating the dataset, followed by $ and the variable name We use a special operator mark from the package magrittr (%&gt;%) to pass on the result to the hist-function (this is called method chaining of piping). hist is the code that creates the actual histogram. We define a title and names for the X and Y-axis. To make the message in our graph easily understandable, we add a vertical line at the 50% mark, using the function abline. palette(c(&quot;aliceblue&quot;, &quot;black&quot;)) # Palette defines a range of colours. you can refer to these colors by using the &#39;order number&#39; in the palette statement sem_1_anon$Woordenschat %&gt;% hist(main = &quot;Verdeling score woordenschat&quot;, xlab = &quot;Score&quot;, ylab = &quot;Aantal studenten&quot;, col = 1) abline(v = 50, lwd = 2, col = 2) Pro tip 5: If you are unsure about what specific code functions mean or do, you can consult the help function. there are 3 common ways of doing this: (1) type ? directly followed by the function (e.g. ?hist) in the console. (2) In the bottom right of your RStudio dashboard, you can see a tab called Help. Click it and write the name of the function in the search field on the top right. (3) Google the name of the function + R an you will probably come across more information than you need (Yes, R is tinkering). 1.3 Histogram exercises Write down an observation regarding the histogram underneath the figure in your Rmd file. Consult the help file for histogram. Try changing the width of the rectangles from 10 to 5, by adapting the breaks in the histogram. (Copy the code to a new chunk before you start tinkering, otherwise you will lose your working code) Make the current histogram more disco by adding 5 more colors based on name or HEX-code to the palette. (this will help: http://www.sthda.com/english/wiki/colors-in-r). To use the succession of colors instead of a single color, use col = 1:7 (: means from 1 until 7) Make a similar histogram on the variable vergelijkingen1 Distinguish the created histograms by adding a sub-title above each histogram containing the variable-name. Can you add a red, striped vertical line where the mean in the histogram of Vergelijkingen1 is situated? (this will help: http://www.sthda.com/english/wiki/abline-r-function-an-easy-way-to-add-straight-lines-to-a-plot-using-r-software) Change the histogram for Vergelijkingen1 to a density plot (check the help function for hist and look for freq) 1.4 Exploring the distribution of a Departement using barplots We will now explore how student-participation in AP-Vaardig is distributed across departement in AP. For those who are really curious about what the codes mean: GW = Gezondheid en Welzijn MC = Management en Communicatie OT = Onderwijs en Training WT = Wetenschap en Techniek KC = Koninklijk Conservatorium KA = Koninklijke Academie The variable Department is a categorical variable so we are switching from a histogram to a bar plot. Observe how the code is constructed below: We select the variable from sem_1_anon by stating the dataset, followed by $ and the variable name We use a special operator mark from the package magrittr (%&gt;%) to pass on the result to the table-function (this is called method chaining of piping) table counts the number of rows pertaining to a specific value of the categorical variable Departement sortorganizes this count ascending. rev switches the order to descending barplot creates the actual bar plot. sem_1_anon$Departement %&gt;% table%&gt;% prop.table%&gt;% sort %&gt;% rev %&gt;% barplot(main = &quot;Verdeling per departement&quot;, xlab = &quot;Department&quot;, ylab = &quot;Aantal studenten&quot;, cex.names = .7, cex.axis = .9, col = 1) We can observe that some of the departments are barely represented in our data file. If we would continue with analyses where Departement is included as a predictor, this would hamper our power. So based on our visualizations it would be better to remove these underrepresented departments. We can do this by using the following steps: We convert our Tibble to a data.table object using the setDT function. We count the number of students per departement using the function .N) per departement. We selecteren those departments containing more than 5 participating students and we save the results in a new object called dep_top.If needed we can use the object dep_top to filter out our dataset. sem_1_anon &lt;- setDT(sem_1_anon) dep_top &lt;- sem_1_anon[, .N, Departement][N &gt; 5, Departement] dep_top ## [1] &quot;MC&quot; &quot;WT&quot; &quot;GW&quot; &quot;OT&quot; 1.5 Barplot exercises Change the bar plot so it will plot the relative frequencies. You can do this by adding prop.table to an object that is the result of a table function. Can you do this using the pipes? Change the relative bar plot to a bar plot containing percentages by adding another line in the pipe: multiply_by (100) %&gt;%. Make a bar plot for the variable Opleidingstype. Make a bar plot for the variable opleiding. See how difficult it is to read these long names. Now flip the bar plot by adding horiz = TRUE to the function barplot (dont forget your comma!). Now thats easier to read :) Make a bar plot on the variable Generatiestudent. Should we keep students who do not have the status of generatiestudenten in our sample? Lets say you have to present your data to the teachers of the department MC. You want their data to stand out in the bar plot. How would you do that, using colors? Implement in a new graph. Lets say that last year all departments promised that at least 20% of their students would participate in AP-Vaardig. How would you make this clear in the bar plot? How could you use abline to accomplish this? Pro Tip 6: sometimes R interprets a variable as numerical while it is in fact a categorical variable. For instance, in our data set the variable Lemo_T indicates whether or not a student participated the Lemo questionnaire. If we want to explore the response rate using a bar plot we need tot convert this variable from type numeric to type Character before creating the bar plot. The code bellow demonstrates how sem_1_anon$Lemo_T &lt;- as.character(sem_1_anon$Lemo_T) sem_1_anon$Lemo_T %&gt;% table %&gt;% prop.table %&gt;% multiply_by(100) %&gt;% sort %&gt;% rev %&gt;% barplot(main = &quot;Respongraad Lemo&quot;, xlab = &quot;Status deelname&quot;, ylab = &quot;Percentage&quot;, ylim=c(0,100), cex.names = .7, cex.axis = .9, col = c(&quot;blue&quot;, &quot;Orange&quot;)) Pro Tip 7: I wanted the colors in this plot to support my message. So I aimed at giving participation a more positive color and non-participation a more negative one. We tend to use green and red to indicate positive and negative. However, for color blind people this is not optimal, as they have difficulty discerning these colors. Therefore it is advised (by color experts) to switch to blue and orange as alternatives. 1.6 Expansion: Grouped &amp; stacked barplots Sometimes you want to compare a distribution across two categorical variables. For instance, we could be wondering whether or not participation in Lemo differs across Departments. We could investigate this using a grouped bar plot and/or a stacked bar plot. Construction of this bar plot is quite similar to a simple bar plot: Make a crosstable of the two variables using the function table (If needed, make a proportional table or a table containing percentages) Sort if needed Use this output as an input for the function barplot We therefore do not go into detail on these variations. However, take notice of the following: We use a filtered version of our dataset containing only Departments with sufficient participants. We run the function filter from the dplyr-package and use the object dep_top we created before to filter out the appropriate departments. we inserted a new function called legend to display a legend in our graph. the fact that how you organize your initial table affects which variable is used as grouping variable. This in turn affects the message your table is displaying and its readability. the argument besides decides whether the bar pot is grouped (besides = TRUE) or stacked (besides = FALSE). you can see I really like shades of blue as a base color for my graphs. 1.6.1 Grouped barplot with department as grouping variable palette(c(&quot;dodgerblue4&quot;, &quot;lightblue&quot;, &quot;blue&quot;, &quot;cadetblue&quot;)) dep_top_alt &lt;- sem_1_anon%&gt;% filter(Departement %in% dep_top) dep_Lemo &lt;- table (dep_top_alt$Departement, dep_top_alt$Lemo_T) dep_Lemo_2 &lt;- prop.table(dep_Lemo)*100 barplot(dep_Lemo_2, col = 1:4, beside = TRUE, ylim=c(0,50)) legend(&quot;topright&quot;, legend = rownames(dep_Lemo_2), fill = 1:4, box.lty = 0, cex = 0.8) 1.6.2 Stacked barplot with participation in Lemo as grouping variable Lemo_dep &lt;- table (dep_top_alt$Lemo_T, dep_top_alt$Departement) Lemo_dep_2 &lt;- prop.table(Lemo_dep)*100 barplot(Lemo_dep_2, col = c(1, 4), beside = FALSE, ylim=c(0,50)) legend(&quot;top&quot;, legend = rownames(Lemo_dep_2), fill = c(1,4), box.lty = 0, cex = 0.8) If you want to exercise this, try making a grouped bar pot for Lemo Participation and Opleidingstype. and answer the following question: AP-vaardig was originally intended as an assessment tool for Graduaten. Bachelor students were allowed, but not obliged to take part in the tool. So there should be mainly students from Graduaten in the sample. Is this true? 1.7 Boxplots 1.7.1 Boxplot of various numerical scales We familiarized ourselves with the distribution of the scores for a single scale Woordenschat through a histogram. we can compare descriptive statistics for various numerical variables (with a similar scale) using boxplots. Observe the steps in the code below: If all scales in your data file are numeric, you can just input the data file as source and R does the rest. Therefore we used the function selectfrom dplyr to select all scales regarding language skills in our data set. Because our variable names are long we adjusted the margins in our plot using the function par. The numbers in between brackets define the margins for respectively: bottom, left, top, right in inches. the function boxplotcreates the boxplot for the data frame scales. las tilts the orientation of the labels for readability. If you wanted a boxplot for a single scale you could just insert datafile$variablename. scales&lt;-sem_1_anon %&gt;% select(Woordenschat:Email) par(mar=c(10,5,1,1)) boxplot(scales, las=2, col =1:4, main = &quot;Verdeling scores schalen taalvaardigheid&quot;) 1.7.2 Providing an indication of distribution If you have a small sample and if it is important to emphasize distribution into more detail, you can consider adding a stripchart to your boxplot. The strip chart adds an extra layer over your boxplots containing individual data points. In large datasets like ours these points just create a large blob. To exemplify the function, we therefore selected the first 25 rows in our dataset using the function slice (again from the dplyr package) . The jitter method disperses the data a bit, so they dont overlap with features in the boxplot. We also went with a very soft color, because we did not want to draw too much attention to the individual points. scales&lt;-sem_1_anon %&gt;% select(Woordenschat:Email) %&gt;% slice_head (n=25) par(mar=c(10,5,1,1)) boxplot(scales, las=2, col =1:4, main = &quot;Verdeling scores schalen taalvaardigheid&quot;) stripchart(scales, las=2, vertical= TRUE, method = &quot;jitter&quot;, pch = 19, bg=2, add = TRUE, col = &quot;mistyrose&quot;) 1.7.3 Grouped boxplots Finally, lets explore how the distribution of our variable Woordenschat differs in the various departments. We know from previous analyses that not all Departments have a decent participation rate. We therefore filter adequate departments using the object dep_top which contains the names of all departments (alternatively we could just sum them up using c(Mc3,GW,WT,OT\")). We use a ~ to instruct R to plot Woordenschat across departments. T finish it of, we constructed a horizontal line on the general median across the entire dataset, just as a point of reference for comparisons. sem_1_anon %&gt;% filter(Departement %in% dep_top) %&gt;% boxplot(Woordenschat ~ Departement, data = ., col = 1, pch = 19, cex = .5, main = &quot;Verdeling score woordenschat per departement&quot;) abline(h = median(sem_1_anon$Woordenschat, na.rm = T), lwd = 2, col = &quot;orange&quot;, lty=2) 1.8 Exercise time Can you repeat the boxplots we constructed on language skills for the mathematical skills incorporated in AP-Vaardig (column Rekenen up until column Goniometrie) One of your colleagues has the odd hypothesis that participating in Lemo (Lemo_T) is related to differences in the variable Deductief_redeneren. Can you explore the idea by making a grouped boxplot? Pro tip 8: In most cases you do not want readers to see your code, just your results. By adding , echo=FALSEin between the brackets and after the r at the start of each chunk, you instruct RStudio to solely print the outcome of your analyses 1.9 Whats next? We already mentioned the tidyverse as a group of packages to tidy, wrangle and present data. Up till now we used three packages from the tidyverse: dplyr, magrittr and tibble. however, the tidyverse also includes a package for visualizing data called ggplot2. The gg stands for grammar of graphics. It has a consistent and methodical way of programming visuals, which can be daunting for beginners. However, when mastered it will give you the option of designing al your graphs to the very detail. Mastering the basics in data visualization using just Base R will help you understand the grammar behind ggplot2. If you feel ready for the next step, ggplot2 is definitely a package to explore. The following books/resources can help you: http://www.cookbook-r.com/Graphs/ https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf https://r4ds.had.co.nz/ https://ggplot2-book.org/ A good start would be to try and replicate the graphs in this workshop using ggplot2. "],["time-series.html", "Workshop 2 Time Series 2.1 Introduction to time series 2.2 Loading the time series data 2.3 Colors 2.4 Data exploration 2.5 Prepare data 2.6 Plotting time series 2.7 Time series analyses 2.8 Decompose time series 2.9 Predictions 2.10 Extra: Resampling temporal data", " Workshop 2 Time Series 2.1 Introduction to time series In this workshop we will learn how to handle and visualize temporal data. Most analytic tools dealing with time series depend on the ts class of objects and so we will have to learn how to transform our source data to a ts object. After that, we will be plotting the results of some diagnostic and predictive analyses typical for time series data. 2.2 Loading the time series data At the end of the workshop you will have the opportunity to work with the same dataset as for the Boxplot workshop, but because that data is slightly more difficult to use for time series analysis, we will first start with a simpler dataset. On Kaggle you will find the dataset called Time Series Data. The data is originally made available as an Excel workbook, but we will be using the same data converted into a tsv file. This dataset consists of the sales figures of a number of products along with several other variables that will not be used here. Excel is often very problematic as a data source, so if you can avoid it, preferably use a format that will still be understood 2000 years from now: plain text, preferably tab-separated values (.tsv) so that values with commas need not to be escaped with double quotes. We use data.table to upload the data. This package currently offers the most professional way to manipulate data. The fread method is flexible and allows you to: load very fast and very large datasets parse text directly as data (i.e. fread (\"A,B\\n1,2\\n3,4\")) select variables as well as instances run a shell command to add a pre-processing step set the data type the variables should be interpreted as include the character encoding of a file (i.e. UTF-8) define the primary key in case of relational data directly open data from within an archive (i.e. fread (\"dev.gz\")) In your new Rmd file, delete the sample code and add the code below (replace single quotes by backticks (grave accents)): --- title: &quot;Timeseries&quot; author: &quot;Your name here&quot; date: &quot;Published on &#39;r Sys.Date()&#39;&quot; output: html_document: highlight: zenburn --- ## Workshop Time Series ... Enter in your name and replace ... with a new R code block (eng: code chunk) using the shortcut Ctrl + Alt + I Make sure in a rMarkdown file to add an empty line before and after each code block, title and list Add the code below in this block (more details below): library(knitr) library(data.table) library(magrittr) library(readxl) library(dplyr) library(ISOweek) library(lubridate) library(forecast) opts_chunk$set(echo = TRUE) sales &lt;- fread(&quot;dat/sales.tsv&quot;) With the various library expressions, the necessary packages are loaded into memory. If these lines generate an error, it usually means the package needs installing first. If so, use an expression such as install.packages(c(\"data.table\", \"magrittr\")) in the console to install the missing packages. Let us now briefly review why we need these packages: knitr: parsing the RMarkdown to an HTML report data.table: loading and manipulating data magrittr: using method chaining dplyr: alternative to manipulating data ISOweek: converting from date to week numbers and vice versa, according to ISO 8601 standards lubridate: expression of a date as a decimal number forecast: wrapper to run forecasts on ts objects Note that for demo purposes two alternatives are used here for manipulating data. Also note that a lot of effort is put into manipulating date fields. As we will see, handling dates, especially when the data is classified on a weekly basis, can become very complex very rapidly. With the opts_chunk$set function (actually function set that is an element of the list opts_chunk) we ensure that the source code is shown in the report. If the report is distributed to individuals who are not interested in the code, you can set echo = FALSE. 2.3 Colors Create a color palette: palette(c(rgb(.7, .7, .7), &quot;steelblue1&quot;, &quot;black&quot;, &quot;#D3EAF1&quot;)) The above code demonstrates the use of the color palette. Here you see that you can enter colors in different formats. After the palette has been defined, you can refer to the colors by means of their indices 1, 2, . If you havent yet heard about it, you might want to examine the Munsell color space. Munsell was a genius with colors. A full description of his color space is beyond the scope of this workshop, but why not admire one of his so-called color contrasts (dyads): Figuur 2.1: The dyad blue-5 versus yellow-red-5 (5B-5YR). In each colored box you will see from the top down: an index for reference, the Munsell color code, the corresponding RGB values and finally the color represented as a hex triplet. See the Wikipedia page for more info and this page of the Rochester Institute of Technology where you will find datasets to produce similar figures. Try to use function colorRampPalette to make a gradient across sampling points corresponding to indices 20, 30 and 66 in above figure. Use ?colorRampPalette if you have used this function before. 2.4 Data exploration We are going to keep data exploration here to a minimum. With the str function you can look inside objects such as this sales object. Such a function is typically executed in the console and is not part of the report itself: # In the console... sales %&gt;% str ## Classes &#39;data.table&#39; and &#39;data.frame&#39;: 935 obs. of 86 variables: ## $ Key : chr &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ... ## $ Date : POSIXct, format: &quot;2014-01-01&quot; &quot;2014-01-01&quot; ... ## $ Volume : num 1346974 677826 1210359 436761 434 ... ## $ Disc : num 4.29e+08 1.16e+08 1.04e+08 5.63e+07 2.94e+05 ... ## $ max_T : num 49.5 49.5 49.5 49.5 49.5 ... ## $ min_T : num 29.7 29.7 29.7 29.7 29.7 ... ## $ avg_T : num 39.6 39.6 39.6 39.6 39.6 ... ## $ precipitation : num 0.448 0.448 0.448 0.448 0.448 ... ## $ Consumer_Price_Index_month : num 85.5 85.5 85.5 85.5 85.5 ... ## $ Exchange_Rate_Index_Period_Average_month : num 109 109 109 109 109 ... ## $ Exchange_Rate_LCU_per_US_Period_Average_month : num 6.83 6.83 6.83 6.83 6.83 ... ... We see that there are a number of products (under Key), a date of sale (Date) and sales Volume. As you can see there are more variables, but with these three we should be able to get started and demonstrate the basics. 2.5 Prepare data The particular thing about time series (but also, for example, GIS data) is that the dependent variables do not only depend on other variables, but also on themselves. We speak of autocorrelation when a value depends on a neighboring value either through space or time. To conduct a time series in R, you are best to work with ts class objects (stands for time series). In order to do that, we first need to pivot the data: sales &lt;- sales %&gt;% dcast(Date ~ Key, value.var = &quot;Volume&quot;) Date A B C D E F G H I J K L M N 2014-01-01 1346974 677825.9 1210358.5 436760.7 433.99 1229415.4 790802.1 NA NA NA NA NA NA NA 2014-02-01 1058681 442605.0 829241.9 205538.3 699.10 885082.1 507910.2 NA NA NA NA NA NA NA 2014-03-01 1089615 550634.4 1100553.1 262253.8 1421.69 1191730.8 612966.6 NA NA NA NA NA NA NA 2014-04-01 1073261 665210.9 1316461.4 351818.4 1758.77 1357049.5 879226.3 278106.2 NA NA NA NA NA NA 2014-05-01 1289022 811401.7 1515828.5 309505.0 2275.23 1713073.1 1041092.3 389241.8 NA NA NA NA NA NA 2014-06-01 1491953 915308.1 1731305.7 339498.8 2894.75 1887919.4 1292278.0 501514.3 NA NA NA NA NA NA This pivoting of data is rather exceptional in statistical analyses and is mainly encountered in autocorrelated data (see also the term repeated measures). Now we select three products and also apply a Date filter because some values are missing at the end of the time series. Then we convert the data to a ts object: sales_ts &lt;- sales[ Date &lt; &quot;2020-02-01&quot;, # Filter by date .(A, C, E)] %&gt;% # Select features ts(frequency = 12, # Convert to ts, 12 months per year start = c(2014, 1)) # Provide start of the time series The dot can have multiple meanings in R and this can be confusing at first. Here it stands as a synonym of list. Within a magrittr-pipe (i.e. after the %&gt;%) the dot stands for whatever is being passed on from previous step, comparable to ans on scientific calculators. 2.6 Plotting time series Once everything is in the correct format, it is as simple as calling the plot function: par(bg = 4, cex.main = 1) main &lt;- &quot;Sales figures\\nfor three products&quot; sales_ts %&gt;% plot(main = main, xlab = &quot;Year&quot;) Close, but no cigar. There is still an issue with the y-axes. Try to think how to fix this issue before you continue. Then see below how it was fixed here. The position of the labels on the axes in base R is determined by a function pretty. So you could turn off the y-axes in the plot (yaxt = \"n\") and plot them all manually using the axis function. Of course, it is much easier to divide the numbers by a factor 1000. Adjust the previous code to divide the sales figures by 1000 and than adjust the title of the figure: sales_ts_th &lt;- sales_ts / 1000 par(bg = 4, cex.main = 1) main &lt;- &quot;Sales figures (x1000)\\nfor three products&quot; sales_ts_th %&gt;% plot(main = main, xlab = &quot;Year&quot;) 2.7 Time series analyses This is not a workshop on analyses, but in reality the analyses and the visualization go hand-in-hand. After all, visualization often serves as a diagnostics tool. Let us measure the amount of cross-correlation among the sales of our three selected products. Examine the auto- and cross-correlation for all combinations of the sales volumes for the products A, C and E. Do this for a horizon of 18 months in the future (positive) and in the past (negative): par(bg = 4) sales_ts_th %&gt;% acf(lag.max = 18) Take a quick look at ?acf and then take a look at the left-most values on the subplots on the diagonal with titles A, C and E. Why are these values 1? From this we learn, for example, that there is a correlation between products A and E with a horizon of 1 season (1 year in this case), but that the relationship is not completely symmetrical. In other words one event seems to precede the other and that may be en important hint to analyse possible causal dependencies. To see this, compare the correlation at 1.0 for A &amp; E (below the dashed blue line indicating the significance level) with that of -1.0 for E &amp; A (above significance level). 2.8 Decompose time series Let us break the sales figures for one product, namely product C, into a seasonal effect (the purely repetitive part), the trend (background level) and the residual noise: par(bg = 4) sales_ts_th[, &quot;C&quot;] %&gt;% stl(s.window = &quot;periodic&quot;) %&gt;% plot Note that the problem of the axes is solved here by alternating the position of the y-axis. Investigate how the plot of a stl object causes the axes to be displayed alternately, use stats:::plot.stl. Did you notice the grey bars on the right in the figure above? Any idea what their function is? 2.9 Predictions Let us predict the future, more specifically the sales figures for the year 2019. Note that we already have those figures, so why would we predict them? Because it is of course good to immediately test the prediction against reality, otherwise we have to wait a year and the organizers of this workshop voted against :-). Let us take the standard plot for multivariate forecast objects: par(bg = 4) sales_ts_th %&gt;% forecast %&gt;% plot(col = 3, xlab = &quot;Year&quot;, main = &quot;Items sold (x 1000)&quot;) Before reading on, try to understand what the shaded areas are on the right? The shaded areas on the right of the above figure correspond to the 80% and 95% prediction intervals. These are conceptually similar, but not the same, as confidence intervals. Try to cut the chaining in above code chunk short and simply run sales_ts_th %&gt;% forecast. How would you exploit this object to manually draw the prediction intervals? The above figure is already quite good, but there are some issues still. Let us start with an important detail: the color and shades of the prediction intervals. With fan you can obtain more color shades and with colorRampPalette we make a simple color gradient: par(bg = 4) ramp &lt;- colorRampPalette(1:2)(25) sales_ts_th %&gt;% forecast(fan = TRUE) %&gt;% plot(col = 3, xlab = &quot;Year&quot;, shadecols = ramp, main = &quot;Items sold (x 1000)&quot;) Now comes the main problem: we really only want to forecast only 2019 and we want to see the current and forecast data superposed. It would also be nice if there were a clear marking to demarcate the start of the prediction. While the default plot is very useful already, there comes a time when we need to customize such graphs and this is exactly what we need to do here. We will create a for loop to draw the prediction-plot one at the time Try to reproduce the predictions with the above requirements: par(bg = 4, mfrow = c(3, 1), oma = c(5, 3, 1, 1), mar = c(0, 4, 0, 2)) for (series_name in sales_ts %&gt;% colnames) { series &lt;- sales_ts_th[, series_name] fc &lt;- series %&gt;% window(end = c(2019, 1)) %&gt;% forecast(fan = TRUE, h = 12) fc %&gt;% plot(shadecols = ramp, col = 3, xaxt = &quot;n&quot;, main = &quot;&quot;) title(ylab = series_name) if (series_name == &quot;E&quot;) { axis(1) } abline(v = 2019, lwd = 2, col = 1, lty = 3) fc &lt;- series %&gt;% window(start = c(2018, 12)) %&gt;% lines(col = 3) } title(xlab = &quot;Year&quot;, outer = 2) Notice how for products A and C the actual sales remain mostly below the point estimate of of the predictions. There is again an issue with the y-axis, try to fix it. 2.10 Extra: Resampling temporal data Temporal data is often organized on a weekly, monthly, quarterly, or annual basis. For example sales figures per quarter. In the industry we speak of a bucket and the bucket could be a week, a quarter, etc . Sometimes, however, as with the student data, a date field is provided, but the data is not neatly aggregated into fixed time units. The aggregation, which is also called resampling or bucketizing, must then be performed manually. This is demonstrated below for the sake of completeness. sem_1 &lt;- fread(&quot;dat/sem_1_anon.tsv&quot;) We first check the range of the variable Datum1, divide it into weeks and add seven days to the end date: sem_1$Datum1 %&gt;% range(na.rm = TRUE) %&gt;% strftime(&quot;%Y-W%V-1&quot;) %&gt;% ISOweek2date %&gt;% add(c(0, 7)) By alternating the dot color per week, we can investigate where there is sufficient data available to perform an analysis on: sem_1[, Week_T := factor(ISOweek(Datum1))] week_lev_all &lt;- sem_1$Week_T %&gt;% levels par(bg = 4) ramp &lt;- rainbow(24, 1) temp_pal &lt;- palette(ramp) sem_1[, plot(Datum1, MemoS_T, col = Week_T, pch = 19, cex = .7, main = &quot;Highlight weeks&quot;, xlab = &quot;Date for review version\\n(&#39;terugblikversie&#39;)&quot;, ylab = &quot;Memorising&quot;)] -&gt; d legend(&quot;bottomright&quot;, legend = week_lev_all, col = ramp, cex = .7, bg = NA, ncol = 4, pch = 19, border = &quot;n&quot;) palette(temp_pal) Finally, we can select the portion with sufficient data available and convert to a ts object: par(bg = 4) sem_1[ grepl(&quot;2020&quot;, Week_T), # Selection .(MemoS_T = mean(MemoS_T)), # Var-manipulation Week_T] %&gt;% # Groeping arrange(Week_T) %&gt;% # dplyr select(MemoS_T) %&gt;% ts( freq = 365.25/7, start = decimal_date(ymd(&quot;2020-09-07&quot;))) %&gt;% plot(lwd = 2, xlab = &quot;Tijd (decimaal)&quot;, ylab = &quot;Memoriseren&quot;, main = &quot;Evolutie memoriseren&quot;) "],["social-network.html", "Workshop 3 Social network 3.1 Introduction to social network 3.2 Loading the data 3.3 Exploring 3.4 Reducing size 3.5 The network 3.6 Vectors 3.7 Cascading style sheets", " Workshop 3 Social network 3.1 Introduction to social network In this workshop, we will try to create an interactive force-directed network diagram from the D3.js framework. Typically, this type of graph is adopted for displaying relations within a social network, but its use extend far beyond social sciences. For example, one could device a similar network depicting the correlation among variables of a large dataset (e.g. the results within the students dataset of workshop 1) or, from the realm of NLP, the co-occurrence of words within tweets. 3.2 Loading the data We will be using the MUSAE GitHub Social Network dataset from Kaggle. This data covers the social network of developers on github. The authors provide us with three files, two of which we will need to display the network: a set of nodes containing the name of the developers a set of edges depicting the relationships among developers Start a new project Load the two files containing the data library(data.table) library(magrittr) library(networkD3) edges &lt;- fread(&quot;dat/git_edges.tsv&quot;) nodes &lt;- fread(&quot;dat/git_nodes.tsv&quot;) 3.3 Exploring Explore the two data.table objects using the str command until you understand how these are connected to each other 3.4 Reducing size Unfortunately, visualizing a social network is really only feasible with relatively small networks. Once we start talking thousand of nodes, you will need a bigger boat. Not that the D3.js network is slow, it is not. It has to do with the number of edges increasing exponentially with increasing number of nodes. Pick the 40 most popular developers, i.e. the ones with the most connections, and adjust the edges and nodes datasets accordingly popular &lt;- edges %&gt;% unlist %&gt;% table %&gt;% sort %&gt;% rev %&gt;% head(40) %&gt;% names edges_sel &lt;- edges[Source %in% popular &amp; Target %in% popular] edges_sel[, Source := match(Source, popular) - 1] edges_sel[, Target := match(Target, popular) - 1] nodes_sel &lt;- nodes[ID %in% popular] nodes_sel[, ID := match(ID, popular) - 1] 3.5 The network Drawing the network is really easy. Because however it is different from any other plotting system in R, it takes a bit time to get accustomed to. For example, the color palette is being written in Javascript. Start by creating a palette with your two favourite colors palette(c(&quot;#2D859C&quot;, &quot;#B86619&quot;)) Now we have to make sure to generate a Javascript statement that looks like this: d3.scaleOrdinal(). domain([&quot;0&quot;, &quot;1&quot;]). range([&quot;#2D859C&quot;, &quot;#B86619&quot;]); Generate the above JS code based on the value of the palette color_scale &lt;- paste0( &quot;d3.scaleOrdinal().domain([\\&quot;0\\&quot;, \\&quot;1\\&quot;])&quot;, &quot;.range([\\&quot;&quot;, palette()[1:2] %&gt;% paste0(collapse = &quot;\\&quot;, \\&quot;&quot;), &quot;\\&quot;]);&quot;) Indeed, also the content of the domain function call could be generated from the unique values in the node groups instead of fixing it to contain [\"0\", \"1\"]. Notice the use of escapes for inserting double quotes. Now that we have the colors covered, we can call the forceNetwork function of the networkD3 package. forceNetwork( height = 600, width = 600, Links = edges_sel, Nodes = nodes_sel, Source = &quot;Source&quot;, Target = &quot;Target&quot;, NodeID = &quot;Name&quot;, Group = &quot;Group&quot;, bounded = TRUE, opacityNoHover = .8, linkColour = &quot;#B3B3B3&quot;, zoom = TRUE, colourScale = JS(color_scale), legend = TRUE, fontFamily = &quot;Roboto&quot;, fontSize = 16, charge = -1, opacity = 1, linkDistance = 200) Let us go over the arguments one-by-one: height = 600: set canvas width to 600 pixels width = 600: set canvas height to 600 pixels Links = edges_sel: attach edge dataset Nodes = nodes_sel: attach node dataset Source = \"Source\": define the variable name containing the source of the relationships Target = \"Target\": define the variable name containing the target of the relationships NodeID = \"Name\": define the variable name containing the label to be displayed Group = \"Group\": define the variable name containing the (color) group bounded = TRUE: wether nodes are allowed to fly out of the canvas opacityNoHover = .8: the opacity of the labels when no node is being hovered over linkColour = \"#B3B3B3\": the color of the edges zoom = TRUE: whether the network can be zoomed-in and out colourScale = JS(color_scale): the JS color scale legend = TRUE: whether to add a legend fontFamily = \"Roboto\": the font family for the labels fontSize = 16: the font size for the labels charge = -1: the amount of force that pull the nodes together (positive) or apart (negative) opacity = 1: the relative opacity of the graph elements linkDistance = 200: the default length of the edges disregarding forces acting upon the nodes See ?forceNetwork for more details. Mind that the code for the developer type was not clear from the data source, otherwise we could have replaced 0 and 1 by their proper type descriptions and the legend would adjust accordingly. 3.6 Vectors The network is being rendered as an svg HTML element (scalable vector graphics). This has some very interested advantages. For one, it means the texts are not rendered as images, but remain searchable just like any other text on the report. Try to search text within your network (e.g. mcanthony) or that of this workshop page using your browser 3.7 Cascading style sheets Hopefully you have heard of CSS before. It is the language used to style the web and it has been growing more popular in the past decades and will probably continue to do so for a while. Because the network is being rendered as pure HTML, elements of it can also be styled using CSS. In Rstudio, which supports multilingual development, you can add a css code chunk instead of an R code chunk. Add a css code chunk in your report to adjust the border color and border stroke width of the nodes. Also, when finished growing after hovering over it, turn the node to a brighter orange: g circle { stroke: #B3B3B3 !important; stroke-width: 1px !important; } g circle[r=&quot;11&quot;]{ fill: #FD9734; } g circle { stroke: #B3B3B3 !important; stroke-width: 1px !important; } g circle[r=\"11\"]{ fill: #FD9734; } "],["saving-your-plot.html", "Workshop 4 Saving your plot 4.1 Using the Report 4.2 Using RStudios export function 4.3 Programmatoricaly", " Workshop 4 Saving your plot Let us conclude with a quickly overview on the number of ways one to persist a plot in R and RStudio. We will be first quickly drawing a plot: plot(JohnsonJohnson) 4.1 Using the Report Simply right-click on the report to export the generated plot into a png file: 4.2 Using RStudios export function If you plot from within the console, your plot will appear in teh Plots tab. Similarly you can use the Zoom functionality: 4.3 Programmatoricaly Of course, there is also a way to export plot from within your script or notebook: svg(&quot;img/J&amp;J_Quaterly.svg&quot;, 300, 600) plot(JohnsonJohnson) dev.off() ## png ## 2 jpeg(&quot;img/J&amp;J_Quaterly.jpg&quot;, 300, 600) plot(JohnsonJohnson) dev.off() ## png ## 2 tiff(&quot;img/J&amp;J_Quaterly.tif&quot;, 300, 600) plot(JohnsonJohnson) dev.off() ## png ## 2 png(&quot;img/J&amp;J_Quaterly.png&quot;, 300, 600) plot(JohnsonJohnson) dev.off() ## png ## 2 "]]
